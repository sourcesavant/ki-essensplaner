# PRD.md: KI-Essensplaner (sourcesavant/ki-essensplaner)

**Repo:** https://github.com/sourcesavant/ki-essensplaner
**Version:** 1.7 (Update: Phase 6 abgeschlossen, 01.02.2026)
**Entwickler:** sourcesavant (Windows 11, PyCharm Community, Python 3.12+)

## Projekt-Ziel
Automatisierter KI-Agent f√ºr personalisierte Wochenpl√§ne: Lernt aus OneNote-Wochenpl√§nen Vorlieben (Zutaten, Aufwand pro Tag), scrapt eatsmarter.de + andere Sites f√ºr passende Neue, generiert Pl√§ne + Einkaufslisten. HA-integrierbar (MQTT/REST).

## Kern-Features (Priorisiert)
1. **Profil-basiertes Lernen (Content-Based Filtering)**: Analysiert OneNote-Pl√§ne ‚Üí Vorlieben (Zutaten-Frequenz/H√§ufigkeit, Aufwand-Klassen: quick/normal/long pro Wochentag/Slot).
2. **Intelligentes Rezept-Scouting**:
   - Sucht auf eatsmarter.de nach Matches mittels Playwright-Scraper
   - Scoring-Formel: Zutaten-Affinit√§t (40%) + Zeit-Passung (25%) + Bioland-Verf√ºgbarkeit (20%) + Saisonalit√§t (15%)
   - Verf√ºgbarkeits-Filter: Rezepte werden ausgeschlossen, wenn Hauptzutaten weder bei Bioland noch saisonal verf√ºgbar sind
3. **Hybrider Wochenplaner**:
   - 7-Tage-Mix: 60% Favoriten (bereits gekochte Rezepte aus DB) + 40% Neue (von eatsmarter)
   - Hybrid-Suche: Slots werden gruppiert (schnelle Mittagessen vs. aufw√§ndige Abendessen) f√ºr effiziente Suchanfragen
   - Detail-Nachladen: Zutaten-Details nur f√ºr Top-Kandidaten laden (Performance-Optimierung)
4. **Lernfunktion** Aktualisiert w√∂chentlich das Profil.
5. **R√ºckmeldung** User kann Rezepte bewerten. User kann Zutaten ausschlie√üen. Rezepte mit dieser Zutat werden trotzdem ber√ºcksichtigt, wenn Zutat durch √§hnliche Zutat ersetzt werden kann.
6. **Einkaufslisten**: Aggregierte Zutaten (Mengen, Kategorien).
7. **Integration**: HA-Dashboard.

## Tech-Stack
- Sprache: Python 3.12 (venv).
- KI: gpt-4o-mini (Scoring/Planung/Normalisierung), gpt-4o (Profil-Ableitung).
- Daten: SQLite (data/local/mealplanner.db), JSON (data/raw/all_recipes.json).
- DB-Tabellen: recipes, meal_plans, meals, parsed_ingredients, available_products, recipe_ratings, excluded_ingredients.
- Scraping: Playwright (eatsmarter.de Suche), recipe-scrapers (Rezept-Details), BeautifulSoup (bioland-huesgen.de).
- Importer: MS Graph API (OneNote).
- Tools: PyCharm, GitHub Projects/Issues, plugged.in MCP.

## Phasen & Issues

### Phase 1: Scrape-Test ‚úÖ
- Issue #1: eatsmarter.py Test-Scraper (3 URLs mit recipe-scrapers)

### Phase 2: OneNote-Merge ‚úÖ
- Issue #2: OneNote Importer (MS Graph API)

### Phase 3: DB + Profil (Vorlieben) ‚úÖ
- Issue #3: Rufe Rezepte von gespeicherten Links ab (Scraping der OneNote-URLs)
- Issue #4: Extrahiere Zutaten und Dauer von Rezepten
- Issue #5: Normalisiere Bezeichnung von Zutaten und Mengen
- Issue #6: Leite Vorlieben-Profil ab (TF-IDF f√ºr Zutaten, Aufwand-Klassen pro Wochentag/Slot)

### Phase 4: Planner + Search ‚úÖ
- Issue #10 ‚úÖ: Bioland H√ºsgen Scraper (Verf√ºgbarkeit saisonaler Produkte)
- Issue #12 ‚úÖ: Saisonalit√§ts-Modul (Kalender f√ºr deutsche Produkte)
- Issue #13 ‚úÖ: Eatsmarter Playwright Scraper (Rezeptsuche mit Zutaten-Filter)
- Issue #14 ‚úÖ: Rezept-Scoring-System
  - Gewichtete Formel: Zutaten-Affinit√§t (40%) + Zeit-Passung (25%) + Bioland (20%) + Saison (15%)
  - Verf√ºgbarkeits-Filter: Rezepte mit nicht-beschaffbaren Hauptzutaten werden ausgeschlossen
- Issue #15 ‚úÖ: Such-Agent f√ºr Rezept-Empfehlungen
  - **Hybrid-Suche**: 3 gruppierte Suchanfragen (quick/normal/elaborate)
  - **60/40-Mix**: 60% Favoriten aus DB + 40% neue von eatsmarter
  - **Detail-Nachladen**: Zutaten nur f√ºr Top-10 Kandidaten laden via recipe-scrapers

**Verwendung:**
```python
from src.agents import run_search_agent

result = run_search_agent()  # Volle Woche
result = run_search_agent(target_day="Mittwoch")  # Ein Tag
result = run_search_agent(target_day="Mittwoch", target_slot="Abendessen")  # Ein Slot

print(result.summary())
```

### Phase 5: Lernfunktion + Interaktion ‚úÖ
- Issue #16 ‚úÖ: W√∂chentliche Profil-Aktualisierung (auto-update beim Agent-Start wenn >7 Tage alt)
- Issue #17 ‚úÖ: Rezept-Bewertungen (1-5 Sterne)
  - 1 Stern: Blacklist (Rezept ausgeschlossen)
  - 2 Sterne: -15% Score-Multiplikator
  - 3 Sterne: Neutral
  - 4 Sterne: +10% Score-Multiplikator
  - 5 Sterne: +20% Score-Multiplikator
- Issue #18 ‚úÖ: Zutaten-Ausschluss mit GPT-basierter Ersetzbarkeit
  - GPT-4o-mini pr√ºft ob Zutat ersetzbar ist (Haupt- vs. Nebenzutat)
  - Nebenzutat: Rezept bleibt, Alternativen werden vorgeschlagen
  - Hauptzutat: Rezept wird ausgeschlossen
  - Ergebnisse werden gecached
- Bioland Auto-Update: W√∂chentliche Aktualisierung der Produktverf√ºgbarkeit beim Agent-Start

### Phase 6: Wochenplan + Einkaufslisten ‚úÖ
- Issue #19 ‚úÖ: Wochenplan mit User-Auswahl
  - 5 Vorschl√§ge pro Slot (14 Slots = 7 Tage √ó 2 Mahlzeiten)
  - `selected_index` f√ºr User-Auswahl (Default: Top-Rezept)
  - JSON-Export f√ºr HA-Integration vorbereitet
  - Persistenz in `data/local/weekly_plan.json`
- Issue #20 ‚úÖ: (kombiniert mit #19)
- Issue #21 ‚úÖ: Einkaufsliste aggregieren
  - Gruppierung nach `name_normalized` (spezifisch, nicht generisch)
  - Mengen mit gleicher Einheit werden addiert
  - Verschiedene Einheiten bleiben separat
- Issue #22 ‚úÖ: Aufteilen Bioland/Rewe
  - Bioland-Verf√ºgbarkeit √ºber `available_products` Tabelle
  - Matching mit Synonymen und Fuzzy-Match

**Verwendung:**
```python
from src.agents import run_search_agent, load_weekly_plan
from src.shopping import generate_shopping_list

# Wochenplan generieren
plan = run_search_agent()

# Oder gespeicherten Plan laden
plan = load_weekly_plan()

# User w√§hlt Rezept f√ºr Slot (Index 0-4)
plan.select_recipe("Montag", "Abendessen", 1)

# Einkaufsliste generieren
shopping_list = generate_shopping_list(plan)
print(shopping_list)

# Nach Store aufteilen
split = shopping_list.split_by_store()
print(split)  # Bioland + Rewe Listen
```

### Phase 7: Integration in HA-Dashboard üîú
- User Interface (MQTT/REST API)

## User Stories
- Als User lade ich OneNote-Pl√§ne hoch ‚Üí Agent leitet Zutaten-Vorlieben + Aufwand-Profile ab.
- Als User sage "Wochenplan mit favorisierten Zutaten" ‚Üí Suche + Plan mit Neuen von eatsmarter.de.
- Als HA-User sehe ich Pl√§ne im Dashboard.

## AI-Instructions (f√ºr Claude/Cursor)
- Granular: Ein File pro Feature (src/profile/preferences.py).
- Output: Vollst√§ndige Python-Dateien + pip-Requirements + Tests.
- Profil: TF-IDF/Cosine f√ºr Zutaten, Counts f√ºr Aufwand pro Slot.
- Idempotent: UPSERT, Error-Handling.
- Libs: recipe-scrapers, pandas, msal, openai, scikit-learn (Similarity).

## Milestones (GitHub Projects)
- Week 1: Setup + Phase 1-2.
- Week 2: Phase 3 (Profil + Vorlieben-Ableitung).
- Week 3: Phase 4 (Search + Planner).

## Risiken & Constraints
- Azure Permissions (Notes.Read.All).
- Scraping-Limits: sleep(0.5), Multi-Site-Fallback.
- Budget: gpt-4o-mini (~0.15$/1M Tokens).
